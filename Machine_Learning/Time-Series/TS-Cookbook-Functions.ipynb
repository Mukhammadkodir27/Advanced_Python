{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25104331-61f3-412e-9ba3-8788e0ded52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "import hvplot.pandas\n",
    "import hvplot as hv\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.diagnostic import kstest_normal\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro, kstest, normaltest\n",
    "from statsmodels.tsa.api import AutoReg \n",
    "# testing for stability of the variance against the model's residuals.\n",
    "from statsmodels.stats.api import (het_breuschpagan, het_goldfeldquandt, het_white)\n",
    "from scipy.stats import boxcox\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "# from statsmodels.tsa.api import (kpss, adfuller, seasonal_decompose, STL)\n",
    "from statsmodels.tools.eval_measures import rmspe, rmse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7df664-37af-40f4-8f9b-594c5d6305ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_outliers function\n",
    "def plot_outliers(outliers, data, method = 'KNN', \n",
    "                 halignment = 'right', \n",
    "                 valignment = 'bottom', \n",
    "                 labels = False):\n",
    "    ax = data.plot(alpha = 1.0)\n",
    "    \n",
    "    if labels:\n",
    "        for i in outliers['value'].item():\n",
    "            plt.plot(i[0], i[1], 'rx')\n",
    "            plt.text(i[0], i[1], f'{i[0].date()}', \n",
    "                    horizontalalignment=halignment, \n",
    "                    verticalalignment=valignment)\n",
    "    else:\n",
    "        data.loc[outliers.index].plot(ax=ax, style='rx')\n",
    "\n",
    "    plt.title(f'Name - {method}')\n",
    "    plt.xlabel('date'); plt.ylabel('# of passengers')\n",
    "    plt.legend(['outliers'])\n",
    "    plt.show()\n",
    "    \n",
    "# As we proceed with the outlier detection recipes, the goal is to see how the different \n",
    "# techniques capture outliers and compare them to the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b65a4-4c5e-401e-aea6-11db0028be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier identifier function\n",
    "def iqr_outliers(data):\n",
    "    q1, q3 = np.percentile(data, [25, 75])\n",
    "    IQR = q3 - q1\n",
    "    lower_fence = q1 - (1.5 * IQR)\n",
    "    upper_fence = q3 + (1.5 * IQR)\n",
    "    return data[(data.value > upper_fence) | (data.value < lower_fence)]\n",
    "\n",
    "outliers = iqr_outliers(dt)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ef0b6-7693-4809-a59d-ebe2854ca87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z score function\n",
    "def zscore(df, column_name, degree=3):\n",
    "    data = df.copy()\n",
    "    data['zscore'] = (data[column_name] - data[column_name].mean()) / data[column_name].std()\n",
    "    outliers = data[(data['zscore'] <= -degree) | (data['zscore'] >= degree)]\n",
    "    return outliers[column_name], data\n",
    "\n",
    "\n",
    "threshold = 2.5\n",
    "outliers, transformed = zscore(dt, 'AAPL', threshold)\n",
    "\n",
    "transformed[['AAPL', 'zscore']].hist(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8cf1f-caf8-419b-9749-23eb14444846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zscore(data, d=3):\n",
    "    n = len(data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data, 'k^')\n",
    "    plt.plot([0, n], [d, d], 'r--')\n",
    "    plt.plot([0, n], [-d, -d], 'r--')\n",
    "\n",
    "data = transformed['zscore'].values\n",
    "plot_zscore(data, d=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e359f23-6341-450c-8b69-3f32dbbf9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import kstest_normal\n",
    "def test_normal(df):\n",
    "    t_test, p_value = kstest_normal(df)\n",
    "    if p_value < 0.05:\n",
    "        print('Reject null hypothesis. Data is not normally distributed')\n",
    "    else:\n",
    "        print('Fail to reject null hypothesis. Data is normally distributed')\n",
    "\n",
    "test_normal(dt.AAPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34607b-9815-4868-ab44-a4169544fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "def print_results(output, test='adf'):\n",
    "    pval = output[1]\n",
    "    test_score = output[0]\n",
    "    lags = output[2]\n",
    "    decision = 'Non-Stationary'\n",
    "    if test == 'adf':\n",
    "        critical = output[4]\n",
    "        if pval < 0.05:\n",
    "            decision = 'Stationary'\n",
    "    elif test == 'kpss':\n",
    "        critical = output[3]\n",
    "        if pval >= 0.05:\n",
    "            decision = 'Stationary'\n",
    "    output_dict = {\n",
    "        'Test Statistic': test_score, \n",
    "        'p-value': pval,\n",
    "        'Numbers of lags': lags, \n",
    "        'decision': decision\n",
    "    }\n",
    "\n",
    "    for key, value in critical.items():\n",
    "        output_dict['Critical Value (%s)' % key] = value\n",
    "\n",
    "    return pd.Series(output_dict, name=test)\n",
    "\n",
    "\n",
    "adf_output = adfuller(dt.AAPL)\n",
    "kpss_output = kpss(dt.AAPL)\n",
    "\n",
    "pd.concat([print_results(adf_output, 'adf'), print_results(kpss_output, 'kpss')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e85ad8-6b6e-4bcd-9d54-24e6e6a07791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_STL_decomposed = STL(\n",
    "    dt.AAPL, \n",
    "    seasonal = 13,\n",
    "    robust = True # remove the impact of outliers\n",
    ").fit()\n",
    "dt_STL_decomposed.plot(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c8047-429f-455e-bae0-9d486374b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cyclic, dt_trend = hpfilter(dt.AAPL)\n",
    "# plt.rcParams[\"figure.figsize\"] = (9,6)\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "dt_cyclic.plot(ax=ax[0], title='Cyclic Component')\n",
    "dt_trend.plot(ax=ax[1], title='Trend Component')\n",
    "ax[0].title.set_size(10)\n",
    "ax[1].title.set_size(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef05a5-9b3f-4958-ab95-39fffc05a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normal(test, p_level = 0.05):\n",
    "    stat, pval = test\n",
    "    return 'Normal' if pval > 0.05 else 'Not Normal'\n",
    "\n",
    "print(is_normal(shapiro(dt.AAPL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242d111-7547-4080-8b5a-dfedcdfbd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def het_test(model, test=het_breuschpagan):\n",
    "    lm, lm_pvalue, fvalue, f_pvalue = (\n",
    "        het_breuschpagan(model.resid, sm.add_constant(model.fittedvalues))\n",
    "    )\n",
    "    return 'Heteroskedastic' if f_pvalue < 0.05 else 'Homoskedastic'\n",
    "\n",
    "het_test(model, test=het_breuschpagan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64489279-cd7a-4c07-a5b9-686bf546645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, lmbda = boxcox(dt.AAPL)\n",
    "xts = pd.Series(xt, index=dt.index)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "dt.AAPL.hist(ax=ax[0]) # original time series\n",
    "xts.hist(ax=ax[1]) # Box-Cox Transformed\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "dt.AAPL.plot(ax=ax[0]) # Original Time Series\n",
    "xts.plot(ax=ax[1]) # Box-Cox Transformed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b04776-e335-4b47-b3a6-2a2acb920723",
   "metadata": {},
   "outputs": [],
   "source": [
    "acorr_ljungbox(dt_diff.AAPL, lags = 10, return_df = True) # to check for autocorrelations\n",
    "\n",
    "# apply the Ljung-Box test against residual from model_bx which was created using\n",
    "# Power Transformations\n",
    "acorr_ljungbox(model_bx.resid, return_df = True, lags = 10)\n",
    "\n",
    "(acorr_ljungbox(results.resid, lags = 25, return_df=True) < 0.05)['lb_pvalue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd6d25-c7c7-4de2-8d2f-c1051a7cc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(score, c='AIC'):\n",
    "    initial_score = score[0][c]\n",
    "    best_model = 0\n",
    "    for k, v, in score.items():\n",
    "        if v[c] < initial_score:\n",
    "            initial_score = v[c]\n",
    "            best_model = k\n",
    "    print(f'Best model: {best_model} with lowes {c} score: {initial_score}')\n",
    "    return score[best_model]['model']\n",
    "\n",
    "best_model = get_best_model(score, 'AIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f04f3d-f28d-48f6-b8b5-deaf49f533e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(model, start, train, test):\n",
    "    forecast = pd.DataFrame(model.forecast(test.shape[0]), \n",
    "                           index = test.index)\n",
    "    ax = train.loc[start:].plot(style='--')\n",
    "    test.plot(ax=ax)\n",
    "    forecast.plot(ax=ax, style='-.')\n",
    "    ax.legend(['origin_train', 'origin_test', 'forecast'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc018d58-62cf-4ea6-ac18-02e7ae3cd673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinator(items):\n",
    "    combo = [i for i in product(*items)]\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2a90b-23d4-4e07-b4df-5c807f2bb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.AAPL.values.ravel()\n",
    "y = test.AAPL.values.ravel()\n",
    "score={}\n",
    "for i, (t, dp) in enumerate(dt_comb):\n",
    "    exp = ExponentialSmoothing(train2, trend=t, damped_trend=dp, seasonal=None)\n",
    "    model = exp.fit(use_brute=True, optimized=True)\n",
    "    y_hat = model.forecast(len(y))\n",
    "    score[i] = {'trend':t,\n",
    "               'damped':dp, \n",
    "               'AIC':model.aic,\n",
    "               'BIC': model.bic,\n",
    "               'AICc': model.aicc,\n",
    "               'RMSPE': rmspe(y, y_hat), \n",
    "               'RMSE': rmse(y, y_hat), \n",
    "               'MAPE': mape(y, y_hat), \n",
    "               'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8ca6d-29e5-4dd0-84c3-55ce6d6a3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.AAPL.values.ravel()\n",
    "y = test.AAPL.values.ravel()\n",
    "score={}\n",
    "for i, (t, dp) in enumerate(dt_comb):\n",
    "    exp = ExponentialSmoothing(train2, trend=t, damped_trend=dp, seasonal=None)\n",
    "    model = exp.fit(use_brute=True, optimized=True)\n",
    "    y_hat = model.forecast(len(y))\n",
    "    score[i] = {'trend':t,\n",
    "               'damped':dp, \n",
    "               'AIC':model.aic,\n",
    "               'BIC': model.bic,\n",
    "               'AICc': model.aicc,\n",
    "               'RMSPE': rmspe(y, y_hat), \n",
    "               'RMSE': rmse(y, y_hat), \n",
    "               'MAPE': mape(y, y_hat), \n",
    "               'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be060013-1eee-417d-af19-664b05ead9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv, dv, qv = [list(range(3))]*3\n",
    "vals = combinator([pv, dv, qv])\n",
    "score = {}\n",
    "for i, (p, d, q) in enumerate(vals):\n",
    "    m = ARIMA(train.AAPL, order=(p,d,q))\n",
    "    res = m.fit()\n",
    "    y = train.AAPL.values.ravel() \n",
    "    y_hat = res.forecast(steps=len(y))\n",
    "    score[i] = {'order':(p,d,q),\n",
    "                'AIC':res.aic, \n",
    "                'RMSPE':rmspe(y, y_hat),\n",
    "                'BIC':res.bic,\n",
    "                'AICc':res.aicc,\n",
    "                'RMSE':rmse(y, y_hat),\n",
    "                'MAPE':mape(y, y_hat),\n",
    "                'model':res}\n",
    "best_m = get_best_model(score, 'AIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe4791-205f-4751-b688-f482276c0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(score).T.sort_values(by='AIC').reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423db849-761d-448f-8311-3ac51a3ee1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = pm.model_selection.train_test_split(dt, test_size=0.10)\n",
    "print(f'Train: {train.shape}')\n",
    "print(f'Test: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbb7c9-acc7-4c9a-be07-9d5254d69ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = pm.auto_arima(train.AAPL, \n",
    "                          seasonal=True,\n",
    "                          m=12, \n",
    "                          test='adf', \n",
    "                          stepwise=True, \n",
    "                          information_criterion='bic',\n",
    "                          trace=True) # to observe the score at each iteration\n",
    "\n",
    "auto_model\n",
    "\n",
    "auto_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
